---
title: "Kommentar: AI ger fel svar – men det går att ändra"
url: "/fixa-ai-fel-svar/"
date: "2025-10-24"
images: ["/img/fixa-ai.jpg"]
author: ['Kaj']
categories: ['AI']
tags: ['AI','Yle', 'Projekt Fredrika']
toc: false
draft: false
_build:
  list: false
  publishResources: true
  render: true
---


Yle publicerade nyligen artikeln [“AI-chattbotar ger ofta felaktiga svar om samhällsfrågor och nyheter”](https://yle.fi/a/7-10086612). Professor Carl-Gustav Lindén lyfter där fram ett reellt problem: språkmodellerna (ChatGPT, Claude, m.fl.) ger ofta missvisande eller direkt fel svar på frågor om vårt samhälle. Jag håller med om problembeskrivningen – men vill lägga till en viktig pusselbit: detta är något vi faktiskt kan åtgärda.

Det är sant att AI idag ofta ger fel svar i dessa frågor. Men det är något man kan åtgärda, och något Projekt Fredrika med hjälp av Kulturfonden och Svenska Litteratursällskapet aktivt sysslar med – i frågor som gäller hur det svenska Finland representeras av de stora språkmodellerna (ChatGPT, Claude m.fl.). 

Vi kan inte direkt påverka innehållet i LLM:arna, men nog indirekt öka chansen för att de ger rätta svar. Det här gör vi genom att påverka de träningsdata som LLM:arna använder. Den mest auktoritativa formen av basdata är Wikipedia och Wikidata, som innehåller den mest vedertagna formen av objektiv sanning. Artikeln noterar att engelska har en större vikt än andra språk, så det räcker inte att ”en gång för alla” förbättra Wikipedia-artiklar enbart på svenska; utan även andra språk. 

Eftersom LLM:ar används i form av diskussioner mellan chatbotten och dess användare, tränas AI inte enbart på ”absoluta fakta” i Wikipedia och Wikidata, utan även öppet tillgängliga diskussioner. Här lyser Reddit som den klaraste stjärnan, vars diskussioner bedöms ligga närmast sanningen både vad innehållets kvalitet och relevans beträffar.
